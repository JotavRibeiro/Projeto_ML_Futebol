{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.19\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from utils import plot_metrics\n",
    "import json\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Machine learning and optimization\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    "    RobustScaler,\n",
    "    QuantileTransformer\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import WOEEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import mlflow\n",
    "\n",
    "# Rich console output\n",
    "from rich.console import Console\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize console\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general directory of the project\n",
    "def general_directory():\n",
    "    \"\"\"\n",
    "    Move up one level in the directory hierarchy.\n",
    "    \"\"\"\n",
    "    # Get the current directory\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # Get the parent directory\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "    # Change to the parent directory\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "# Set actual directory of the project\n",
    "def actual_directory():\n",
    "    \"\"\"\n",
    "    Move down to the 'experiments' subdirectory from the current directory.\n",
    "    \"\"\"\n",
    "    # Get the current directory\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # Name of the subdirectory to move into\n",
    "    sub_dir_name = \"experiments\"  # Replace with the name of your subdirectory\n",
    "\n",
    "    # Construct the full path to the subdirectory\n",
    "    sub_dir_path = os.path.join(current_dir, sub_dir_name)\n",
    "\n",
    "    # Change to the subdirectory\n",
    "    os.chdir(sub_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4559, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>League</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>HG</th>\n",
       "      <th>AG</th>\n",
       "      <th>Res</th>\n",
       "      <th>...</th>\n",
       "      <th>PA</th>\n",
       "      <th>MaxH</th>\n",
       "      <th>MaxD</th>\n",
       "      <th>MaxA</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>Target</th>\n",
       "      <th>is_test</th>\n",
       "      <th>ratio_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>2012</td>\n",
       "      <td>19/05/2012</td>\n",
       "      <td>22:30</td>\n",
       "      <td>Palmeiras</td>\n",
       "      <td>Portuguesa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.87</td>\n",
       "      <td>5.31</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>2012</td>\n",
       "      <td>19/05/2012</td>\n",
       "      <td>22:30</td>\n",
       "      <td>Sport Recife</td>\n",
       "      <td>Flamengo RJ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.003876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>2012</td>\n",
       "      <td>20/05/2012</td>\n",
       "      <td>01:00</td>\n",
       "      <td>Figueirense</td>\n",
       "      <td>Nautico</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.05</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.59</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>2012</td>\n",
       "      <td>20/05/2012</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Botafogo RJ</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.49</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.827465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>2012</td>\n",
       "      <td>20/05/2012</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Corinthians</td>\n",
       "      <td>Fluminense</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.41</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.53</td>\n",
       "      <td>4.41</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country   League  Season        Date   Time          Home         Away   HG  \\\n",
       "0  Brazil  Serie A    2012  19/05/2012  22:30     Palmeiras   Portuguesa  1.0   \n",
       "1  Brazil  Serie A    2012  19/05/2012  22:30  Sport Recife  Flamengo RJ  1.0   \n",
       "2  Brazil  Serie A    2012  20/05/2012  01:00   Figueirense      Nautico  2.0   \n",
       "3  Brazil  Serie A    2012  20/05/2012  20:00   Botafogo RJ    Sao Paulo  4.0   \n",
       "4  Brazil  Serie A    2012  20/05/2012  20:00   Corinthians   Fluminense  0.0   \n",
       "\n",
       "    AG Res  ...    PA  MaxH  MaxD  MaxA  AvgH  AvgD  AvgA  Target  is_test  \\\n",
       "0  1.0   D  ...  5.25  1.76  3.87  5.31  1.69  3.50  4.90       0        0   \n",
       "1  1.0   D  ...  2.68  2.83  3.42  2.70  2.59  3.23  2.58       0        1   \n",
       "2  1.0   H  ...  6.72  1.67  4.05  7.22  1.59  3.67  5.64       1        0   \n",
       "3  2.0   H  ...  3.15  2.49  3.39  3.15  2.35  3.26  2.84       1        0   \n",
       "4  1.0   A  ...  4.41  1.96  3.53  4.41  1.89  3.33  3.89       0        0   \n",
       "\n",
       "   ratio_odds  \n",
       "0    0.344898  \n",
       "1    1.003876  \n",
       "2    0.281915  \n",
       "3    0.827465  \n",
       "4    0.485861  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_directory()\n",
    "\n",
    "df_features = pd.read_parquet(os.getcwd() + '\\\\data\\\\silver\\\\BRA_baseline.csv')\n",
    "df_features['ratio_odds'] = df_features['AvgH']/df_features['AvgA']\n",
    "\n",
    "print(df_features.shape)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegLogOptimizator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        x,\n",
    "        y,\n",
    "        target,\n",
    "        features,\n",
    "        categorical_features=[],\n",
    "        niter=10,\n",
    "        metric_eval=\"AUC\",\n",
    "        metric_method=\"default\",\n",
    "        thr=0.5,\n",
    "        col_safra=None,\n",
    "        early_stopping_rounds=3,\n",
    "        eval_n_features=False,\n",
    "        filename_storage=\"reg_log_search\",\n",
    "        save_in_txt=True,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        metric_eval: 'AUC' or 'KS'\n",
    "        metric_method: 'default', 'min', 'range'\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.features = features\n",
    "        self.categorical_features = categorical_features\n",
    "        self.target = target\n",
    "        self.col_safra = col_safra\n",
    "        self.niter = niter\n",
    "        self.metric_eval = metric_eval\n",
    "        self.metric_method = metric_method\n",
    "        self.thr = thr\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.eval_n_features = eval_n_features\n",
    "        self.verbose = verbose\n",
    "        self.best_auc = 0.0\n",
    "        self.score = 0.0\n",
    "        self.iterations_not_improving = 0\n",
    "        self.iterations = 0\n",
    "        self.filename_storage = filename_storage\n",
    "        self.save_in_txt = save_in_txt\n",
    "\n",
    "    def get_optimal_params(self):\n",
    "        if self.save_in_txt:\n",
    "            self.create_log()\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        objective = self.generate_objective_function(\n",
    "            self.x,\n",
    "            self.y,\n",
    "            self.target,\n",
    "            self.features,\n",
    "            self.categorical_features,\n",
    "        )\n",
    "        storage = JournalStorage(JournalFileStorage(f\"{self.filename_storage}.log\"))\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            study_name=\"Hyperparameter search\",\n",
    "            storage=storage,\n",
    "            load_if_exists=True,\n",
    "        )\n",
    "        study.optimize(\n",
    "            objective,\n",
    "            n_trials=self.niter,\n",
    "            callbacks=[self.early_stopping_fn],\n",
    "            n_jobs=1,\n",
    "        )\n",
    "        best_trial = study.best_trial\n",
    "        return best_trial, study\n",
    "\n",
    "    def early_stopping_fn(\n",
    "        self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial\n",
    "    ):\n",
    "        if self.iterations_not_improving >= self.early_stopping_rounds:\n",
    "            study.stop()\n",
    "\n",
    "    def update_best_params(self, score, test_metrics):\n",
    "        self.iterations += 1\n",
    "        if score > self.best_auc:\n",
    "            self.iterations_not_improving = 0\n",
    "            self.best_auc = score\n",
    "            if self.verbose:\n",
    "                console.print(\n",
    "                    f\"|Iteration {self.iterations}| New parameters found - {self.metric_eval} of {np.mean(test_metrics):.4f} ({self.best_auc:.4f})\"\n",
    "                )\n",
    "        else:\n",
    "            self.iterations_not_improving += 1\n",
    "\n",
    "    def ks(self, y, y_pred):\n",
    "        return ks_2samp(y_pred[y == 1], y_pred[y != 1]).statistic\n",
    "\n",
    "    def predict(self, model, x):\n",
    "        return model.predict_proba(x)[:, 1]\n",
    "\n",
    "    def get_metric_min(self, df, target, metric_eval, col_safra):\n",
    "        if metric_eval == \"KS\":\n",
    "            score_min = (\n",
    "                df.groupby(col_safra)\n",
    "                .apply(lambda x: self.ks(x[target], x[\"prob\"]) * 100)\n",
    "                .min()\n",
    "            )\n",
    "        else:\n",
    "            score_min = (\n",
    "                df.groupby(col_safra)\n",
    "                .apply(lambda x: metrics.roc_auc_score(x[target], x[\"prob\"]))\n",
    "                .min()\n",
    "            )\n",
    "        return score_min\n",
    "\n",
    "    def get_metric_range(self, df, target, metric_eval, col_safra):\n",
    "        if metric_eval == \"KS\":\n",
    "            score_min = (\n",
    "                df.groupby(col_safra)\n",
    "                .apply(lambda x: self.ks(x[target], x[\"prob\"]) * 100)\n",
    "                .min()\n",
    "            )\n",
    "            score_max = (\n",
    "                df.groupby(col_safra)\n",
    "                .apply(lambda x: self.ks(x[target], x[\"prob\"]) * 100)\n",
    "                .max()\n",
    "            )\n",
    "        else:\n",
    "            score_min = (\n",
    "                df.groupby(col_safra)\n",
    "                .apply(lambda x: metrics.roc_auc_score(x[target], x[\"prob\"]))\n",
    "                .min()\n",
    "            )\n",
    "            score_max = (\n",
    "                df.groupby(col_safra)\n",
    "                .apply(lambda x: metrics.roc_auc_score(x[target], x[\"prob\"]))\n",
    "                .max()\n",
    "            )\n",
    "        range_ = score_max - score_min\n",
    "        return range_\n",
    "\n",
    "    def get_metric(self, df, target, metric_eval):\n",
    "        if metric_eval == \"KS\":\n",
    "            score = self.ks(df[target], df[\"prob\"]) * 100\n",
    "        else:\n",
    "            score = metrics.roc_auc_score(df[target], df[\"prob\"])\n",
    "        return score\n",
    "\n",
    "    def decision(self, metric_train, metric_test, metric_otm, thr=5):\n",
    "        return 0 if np.abs(metric_train - metric_test) > thr else metric_otm\n",
    "\n",
    "    def generate_objective_function(self, x, y, target, features, categorical_features):\n",
    "        def objective(\n",
    "            trial,\n",
    "            x=x,\n",
    "            y=y,\n",
    "            target=target,\n",
    "            features=features,\n",
    "            categorical_features=categorical_features,\n",
    "        ):\n",
    "            numerical_features = [x for x in features if x not in categorical_features]\n",
    "\n",
    "            parameters = {\n",
    "                \"penalty\": trial.suggest_categorical(\n",
    "                    \"penalty\", [\"l1\", \"l2\", \"elasticnet\"]\n",
    "                ),\n",
    "                \"C\": trial.suggest_loguniform(\"C\", 0.001, 10),\n",
    "                \"class_weight\": trial.suggest_categorical(\n",
    "                    \"class_weight\", [\"balanced\"]\n",
    "                ),\n",
    "                \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000, 50),\n",
    "            }\n",
    "\n",
    "            if parameters[\"penalty\"] == \"l1\":\n",
    "                parameters[\"solver\"] = trial.suggest_categorical(\n",
    "                    \"solver_l1\", [\"liblinear\", \"saga\"]\n",
    "                )\n",
    "            elif parameters[\"penalty\"] == \"l2\":\n",
    "                parameters[\"solver\"] = trial.suggest_categorical(\n",
    "                    \"solver_l2\",\n",
    "                    [\n",
    "                        \"lbfgs\",\n",
    "                        \"liblinear\",\n",
    "                        \"newton-cg\",\n",
    "                        \"newton-cholesky\",\n",
    "                        \"sag\",\n",
    "                        \"saga\",\n",
    "                    ],\n",
    "                )\n",
    "            elif parameters[\"penalty\"] == \"elasticnet\":\n",
    "                parameters[\"solver\"] = trial.suggest_categorical(\n",
    "                    \"solver_elasticnet\", [\"saga\"]\n",
    "                )\n",
    "                parameters[\"l1_ratio\"] = trial.suggest_float(\n",
    "                    name=\"l1_ratio\", low=0.0, high=1.0, step=0.05\n",
    "                )\n",
    "            else:\n",
    "                parameters[\"solver\"] = trial.suggest_categorical(\n",
    "                    \"solver_none\",\n",
    "                    [\n",
    "                        \"lbfgs\",\n",
    "                        \"liblinear\",\n",
    "                        \"newton-cg\",\n",
    "                        \"newton-cholesky\",\n",
    "                        \"sag\",\n",
    "                        \"saga\",\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "\n",
    "            # Transformer das categóricas\n",
    "            encoder = trial.suggest_categorical(\n",
    "                \"encoder_categorical\", [\"woe\", \"onehot\", \"ordenc\"]\n",
    "            )\n",
    "\n",
    "            if encoder == \"woe\":\n",
    "                encoder_sel = WOEEncoder()\n",
    "            if encoder == \"onehot\":\n",
    "                encoder_sel = OneHotEncoder()\n",
    "            if encoder == \"ordenc\":\n",
    "                encoder_sel = OrdinalEncoder()\n",
    "\n",
    "            cat_transformer = Pipeline(steps=[(\"encoder\", encoder_sel)])\n",
    "\n",
    "            # Transformer das numéricas\n",
    "            imputer = trial.suggest_categorical(\n",
    "                \"imputer_missing\",\n",
    "                [\n",
    "                    \"simple_med\",\n",
    "                    \"simple_cte\",\n",
    "                ]  \n",
    "            )\n",
    "\n",
    "            scaler = trial.suggest_categorical(\n",
    "                \"scaler_val\",\n",
    "                [\n",
    "                    \"standard\",\n",
    "                    \"robust\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if imputer == \"simple_med\":\n",
    "                imputer_sel = SimpleImputer(strategy=\"median\")\n",
    "            if imputer == \"simple_cte\":\n",
    "                imputer_sel = SimpleImputer(strategy=\"constant\", fill_value=-999)\n",
    "            if scaler == \"standard\":\n",
    "                scaler_sel = StandardScaler()\n",
    "            if scaler == \"robust\":\n",
    "                scaler_sel = RobustScaler()\n",
    "\n",
    "            num_transformer = Pipeline(steps=[(\"imputer\", imputer_sel), (\"scaler\", scaler_sel)])\n",
    "\n",
    "            # Compondo os pré-processadores\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num\", num_transformer, numerical_features),\n",
    "                    (\"cat\", cat_transformer, categorical_features),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Definição do modelo\n",
    "            model = LogisticRegression(**parameters)\n",
    "\n",
    "            pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"RegLog\", model)])\n",
    "\n",
    "            if self.eval_n_features:\n",
    "                \n",
    "                pipeline.fit(x[features], y[[target]])\n",
    "                \n",
    "                if encoder == \"onehot\":\n",
    "                    features_ = [\n",
    "                        x for x in features if x not in categorical_features\n",
    "                    ] + list(\n",
    "                        pipeline[\"preprocessor\"]\n",
    "                        .transformers_[1][1][\"encoder\"]\n",
    "                        .get_feature_names_out()\n",
    "                    )\n",
    "                    coef = pipeline.steps[-1][1].coef_[0]\n",
    "                    feature_importance = pd.DataFrame(\n",
    "                        {\"var\": features_, \"Importance\": np.abs(coef)}\n",
    "                    )\n",
    "                    feature_importance = feature_importance.sort_values(\n",
    "                        \"Importance\", ascending=False\n",
    "                    ).reset_index(drop=True)\n",
    "                \n",
    "                else:\n",
    "                    coef = pipeline.steps[-1][1].coef_[0]\n",
    "                    feature_importance = pd.DataFrame(\n",
    "                        {\"var\": features, \"Importance\": np.abs(coef)}\n",
    "                    )\n",
    "                    feature_importance = feature_importance.sort_values(\n",
    "                        \"Importance\", ascending=False\n",
    "                    ).reset_index(drop=True)\n",
    "                \n",
    "                features_fi = list(feature_importance[\"var\"])\n",
    "                \n",
    "                for i in range(len(features_fi)):\n",
    "                    for k in range(len(features)):\n",
    "                        if features[k] in features_fi[i]:\n",
    "                            features_fi[i] = features[k]\n",
    "                \n",
    "                features_fi = list(dict.fromkeys(features_fi))\n",
    "                \n",
    "                n_features = trial.suggest_int(\"n_features\", 1, len(features))\n",
    "                \n",
    "                selected_features = features_fi[:n_features]\n",
    "                \n",
    "                trial.set_user_attr(\"selected_features\", selected_features)\n",
    "                \n",
    "                features = [x for x in selected_features]\n",
    "                \n",
    "                categorical_features = [x for x in self.categorical_features if x in selected_features]\n",
    "                \n",
    "                preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        (\n",
    "                            \"num\",\n",
    "                            num_transformer,\n",
    "                            [x for x in features if x not in categorical_features],\n",
    "                        ),\n",
    "                        (\"cat\", cat_transformer, categorical_features),\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"RegLog\", model)])\n",
    "\n",
    "            train_metrics = np.zeros(5)\n",
    "            test_metrics = np.zeros(5)\n",
    "\n",
    "            kf = StratifiedKFold(shuffle=True, random_state=42)\n",
    "\n",
    "            for i, (idx_train, idx_test) in enumerate(kf.split(x, y)):\n",
    "                x_train, y_train = x.iloc[idx_train], y.iloc[idx_train]\n",
    "                x_test, y_test = x.iloc[idx_test], y.iloc[idx_test]\n",
    "\n",
    "                pipeline.fit(x_train, y_train)\n",
    "                y_pred_train = self.predict(pipeline, x_train)\n",
    "                y_pred_test = self.predict(pipeline, x_test)\n",
    "                y_train[\"prob\"] = y_pred_train\n",
    "                y_test[\"prob\"] = y_pred_test\n",
    "\n",
    "                if self.metric_method == \"min\":\n",
    "                    train_metrics[i] = self.get_metric_min(\n",
    "                        y_train, target, self.metric_eval, self.col_safra\n",
    "                    )\n",
    "                    test_metrics[i] = self.get_metric_min(\n",
    "                        y_test, target, self.metric_eval, self.col_safra\n",
    "                    )\n",
    "                elif self.metric_method == \"range\":\n",
    "                    train_metrics[i] = self.get_metric_range(\n",
    "                        y_train, target, self.metric_eval, self.col_safra\n",
    "                    )\n",
    "                    test_metrics[i] = self.get_metric_range(\n",
    "                        y_test, target, self.metric_eval, self.col_safra\n",
    "                    )\n",
    "                else:\n",
    "                    train_metrics[i] = self.get_metric(\n",
    "                        y_train, target, self.metric_eval\n",
    "                    )\n",
    "                    test_metrics[i] = self.get_metric(\n",
    "                        y_test, target, self.metric_eval\n",
    "                    )\n",
    "\n",
    "            metrics = {\n",
    "                \"train_metrics\": list(train_metrics),\n",
    "                \"test_metrics\": list(test_metrics),\n",
    "                \"train_metric\": np.mean(train_metrics),\n",
    "                \"test_metric\": np.mean(test_metrics),\n",
    "            }\n",
    "\n",
    "            for key in metrics:\n",
    "                trial.set_user_attr(key, metrics[key])\n",
    "\n",
    "            metric_otm = np.mean(test_metrics) - np.std(test_metrics)\n",
    "            value = self.decision(\n",
    "                np.mean(train_metrics), np.mean(test_metrics), metric_otm, thr=self.thr\n",
    "            )\n",
    "            self.update_best_params(value, test_metrics)\n",
    "            if self.save_in_txt:\n",
    "                f = open(f\"{self.log_file}.txt\", \"a\")\n",
    "                f.write(\n",
    "                    f\"{self.iterations};{parameters};{list(metrics['train_metrics'])};{list(metrics['test_metrics'])}\\n\"\n",
    "                )\n",
    "                f.close()\n",
    "            return value\n",
    "\n",
    "        return objective\n",
    "\n",
    "    def create_log(self):\n",
    "        time_ref = datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "        self.log_file = f\"resume_reg_log_opt_{time_ref}\"\n",
    "        f = open(f\"{self.log_file}.txt\", \"w\")\n",
    "        f = open(f\"{self.log_file}.txt\", \"a\")\n",
    "        f.write(f\"iter;parameters;train_metrics;test_metrics\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">|Iteration <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>| New parameters found - AUC of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6629</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6469</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "|Iteration \u001b[1;36m1\u001b[0m| New parameters found - AUC of \u001b[1;36m0.6629\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m0.6469\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actual_directory()\n",
    "\n",
    "features = ['ratio_odds']\n",
    "target = ['Target']\n",
    "\n",
    "features_dictionary = {\n",
    "    \"ratio_odds\": \"Razão entre as odds do mandante e do visitante\",\n",
    "}\n",
    "\n",
    "with open(\"1st_run_features_dictionary.json\", \"w\") as f:\n",
    "    json.dump(features_dictionary, f)\n",
    "\n",
    "model_opt = RegLogOptimizator (\n",
    "\n",
    "            x = df_features.loc[df_features['is_test'] == 0,features],\n",
    "            y = df_features.loc[df_features['is_test'] == 0,target],\n",
    "            target = 'Target',\n",
    "            features = features,\n",
    "            categorical_features = [],\n",
    "            niter = 1000,\n",
    "            metric_eval = \"AUC\",\n",
    "            metric_method = \"default\",\n",
    "            thr = 0.05, \n",
    "            col_safra = None,\n",
    "            early_stopping_rounds = 200,\n",
    "            filename_storage = \"1st_run_experiment\",\n",
    "            save_in_txt = True\n",
    "\n",
    "        )\n",
    "    \n",
    "best_trial, study = model_opt.get_optimal_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_features.loc[df_features['is_test'] == 0, features], df_features.loc[df_features['is_test'] == 0, target]\n",
    "X_test, y_test = df_features.loc[df_features['is_test'] == 1, features], df_features.loc[df_features['is_test'] == 1, target]\n",
    "\n",
    "df_results = {\n",
    "\n",
    "    'id': [],\n",
    "    'params': [],\n",
    "    'qtd_features': [],\n",
    "    'features': [],\n",
    "    'transformer': [],\n",
    "    'auc_train_cv': [],\n",
    "    'auc_test_cv': [],\n",
    "    'auc_train': [],\n",
    "    'auc_test': [],\n",
    "\n",
    "}\n",
    "\n",
    "for j, study_trial in enumerate(study.trials):\n",
    "\n",
    "    if study_trial.state != TrialState.COMPLETE or study_trial.value == 0:\n",
    "        continue  # Skip the trials that did not complete successfully\n",
    "\n",
    "    model_params = {k: v for k, v in study_trial.params.items() if k not in ['encoder_categorical','imputer_missing','scaler_val','n_features']}\n",
    "    solver_key = next((key for key in model_params if 'solver' in key), None)\n",
    "    if solver_key:\n",
    "        model_params['solver'] = model_params.pop(solver_key)\n",
    "    model_params['random_state'] = 42\n",
    "\n",
    "    scaler_dict = {k: v for k, v in study_trial.params.items() if k == 'scaler_val'}\n",
    "    \n",
    "    if scaler_dict['scaler_val'] == 'standard':\n",
    "        transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    elif scaler_dict['scaler_val'] == 'robust':\n",
    "        transformer = Pipeline(steps=[(\"scaler\", RobustScaler())])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"features\", transformer, features),\n",
    "                ]\n",
    "            )\n",
    "    \n",
    "    clf = LogisticRegression(**model_params)\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"RegLog\", clf)])\n",
    "\n",
    "    pipeline.fit(X_train[features], y_train)\n",
    "    y_prob_train = pipeline.predict_proba(X_train[features])[:, 1]\n",
    "    auc_train = metrics.roc_auc_score(y_train, y_prob_train)\n",
    "\n",
    "    y_prob_test = pipeline.predict_proba(X_test[features])[:, 1]\n",
    "    auc_test = metrics.roc_auc_score(y_test, y_prob_test)\n",
    "\n",
    "    num_features = len(features)\n",
    "    \n",
    "    for i, k in enumerate(df_results.keys()): df_results[k].append([f\"{j:03d}\", \n",
    "                                                                    model_params, \n",
    "                                                                    num_features, \n",
    "                                                                    features, \n",
    "                                                                    transformer,\n",
    "                                                                    round(study_trial.user_attrs['train_metric'] * 100, 2),\n",
    "                                                                    round(study_trial.user_attrs['test_metric'] * 100, 2),\n",
    "                                                                    round(auc_train * 100, 2), \n",
    "                                                                    round(auc_test * 100, 2)][i])\n",
    "\n",
    "df_results = pd.DataFrame(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>params</th>\n",
       "      <th>qtd_features</th>\n",
       "      <th>features</th>\n",
       "      <th>transformer</th>\n",
       "      <th>auc_train_cv</th>\n",
       "      <th>auc_test_cv</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>{'penalty': 'l1', 'C': 1.279196107764435, 'cla...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(StandardScaler())</td>\n",
       "      <td>66.33</td>\n",
       "      <td>66.29</td>\n",
       "      <td>66.33</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>{'penalty': 'elasticnet', 'C': 0.0088201286385...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(StandardScaler())</td>\n",
       "      <td>66.33</td>\n",
       "      <td>66.29</td>\n",
       "      <td>66.33</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.006345123324989716, '...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(RobustScaler())</td>\n",
       "      <td>66.33</td>\n",
       "      <td>66.29</td>\n",
       "      <td>66.33</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>{'penalty': 'elasticnet', 'C': 0.0043378089022...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(StandardScaler())</td>\n",
       "      <td>66.33</td>\n",
       "      <td>66.29</td>\n",
       "      <td>66.33</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>{'penalty': 'l2', 'C': 3.4710950696276552, 'cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(RobustScaler())</td>\n",
       "      <td>66.33</td>\n",
       "      <td>66.29</td>\n",
       "      <td>66.33</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>071</td>\n",
       "      <td>{'penalty': 'l1', 'C': 3.785112498367953, 'cla...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(StandardScaler())</td>\n",
       "      <td>66.33</td>\n",
       "      <td>66.29</td>\n",
       "      <td>66.33</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>072</td>\n",
       "      <td>{'penalty': 'l1', 'C': 6.567960149863006, 'cla...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(StandardScaler())</td>\n",
       "      <td>66.33</td>\n",
       "      <td>66.29</td>\n",
       "      <td>66.33</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.0013032337543173276, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(RobustScaler())</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>{'penalty': 'elasticnet', 'C': 0.0010009752338...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(RobustScaler())</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.0012134435922724447, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ratio_odds]</td>\n",
       "      <td>(StandardScaler())</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             params  qtd_features  \\\n",
       "0    000  {'penalty': 'l1', 'C': 1.279196107764435, 'cla...             1   \n",
       "126  126  {'penalty': 'elasticnet', 'C': 0.0088201286385...             1   \n",
       "128  128  {'penalty': 'l1', 'C': 0.006345123324989716, '...             1   \n",
       "129  129  {'penalty': 'elasticnet', 'C': 0.0043378089022...             1   \n",
       "130  130  {'penalty': 'l2', 'C': 3.4710950696276552, 'cl...             1   \n",
       "..   ...                                                ...           ...   \n",
       "71   071  {'penalty': 'l1', 'C': 3.785112498367953, 'cla...             1   \n",
       "72   072  {'penalty': 'l1', 'C': 6.567960149863006, 'cla...             1   \n",
       "115  115  {'penalty': 'l1', 'C': 0.0013032337543173276, ...             1   \n",
       "161  161  {'penalty': 'elasticnet', 'C': 0.0010009752338...             1   \n",
       "200  200  {'penalty': 'l1', 'C': 0.0012134435922724447, ...             1   \n",
       "\n",
       "         features         transformer  auc_train_cv  auc_test_cv  auc_train  \\\n",
       "0    [ratio_odds]  (StandardScaler())         66.33        66.29      66.33   \n",
       "126  [ratio_odds]  (StandardScaler())         66.33        66.29      66.33   \n",
       "128  [ratio_odds]    (RobustScaler())         66.33        66.29      66.33   \n",
       "129  [ratio_odds]  (StandardScaler())         66.33        66.29      66.33   \n",
       "130  [ratio_odds]    (RobustScaler())         66.33        66.29      66.33   \n",
       "..            ...                 ...           ...          ...        ...   \n",
       "71   [ratio_odds]  (StandardScaler())         66.33        66.29      66.33   \n",
       "72   [ratio_odds]  (StandardScaler())         66.33        66.29      66.33   \n",
       "115  [ratio_odds]    (RobustScaler())         50.00        50.00      50.00   \n",
       "161  [ratio_odds]    (RobustScaler())         50.00        50.00      50.00   \n",
       "200  [ratio_odds]  (StandardScaler())         50.00        50.00      50.00   \n",
       "\n",
       "     auc_test  \n",
       "0       65.34  \n",
       "126     65.34  \n",
       "128     65.34  \n",
       "129     65.34  \n",
       "130     65.34  \n",
       "..        ...  \n",
       "71      65.34  \n",
       "72      65.34  \n",
       "115     50.00  \n",
       "161     50.00  \n",
       "200     50.00  \n",
       "\n",
       "[201 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'auc_test', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = df_results.loc[df_results['id'] == '000', ['params']].values[0][0]\n",
    "\n",
    "transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"features\", transformer, features),\n",
    "                ]\n",
    "            )\n",
    "X_train, y_train = df_features.loc[df_features['is_test'] == 0, features], df_features.loc[df_features['is_test'] == 0, target]\n",
    "X_test, y_test = df_features.loc[df_features['is_test'] == 1, features], df_features.loc[df_features['is_test'] == 1, target]\n",
    "\n",
    "clf = LogisticRegression(**params)\n",
    "\n",
    "pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"RegLog\", clf)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_prob_train = clf.predict_proba(X_train)[:, 1]\n",
    "auc_train = metrics.roc_auc_score(y_train, y_prob_train)\n",
    "\n",
    "y_prob_test = clf.predict_proba(X_test)[:, 1]\n",
    "auc_test = metrics.roc_auc_score(y_test, y_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/31 13:46:03 INFO mlflow.tracking.fluent: Experiment with name 'ML_Brasileirao_A' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1722444363702, experiment_id='1', last_update_time=1722444363702, lifecycle_stage='active', name='ML_Brasileirao_A', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"ML_Brasileirao_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"1st-run-model-study\", description=\"\"):\n",
    "    \n",
    "    mlflow.log_params(model_params)\n",
    "\n",
    "    mlflow.log_param(\"features\", features)\n",
    "\n",
    "    mlflow.log_metric(\"train_auc\", auc_train)\n",
    "\n",
    "    mlflow.log_metric(\"test_auc\", auc_test)\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline, \"classifier\")\n",
    "\n",
    "    mlflow.log_artifact(\"1st_run_features_dictionary.json\", artifact_path=\"classifier\")\n",
    "    \n",
    "    plot_metrics(df = df_features[df_features['is_test'] == 1], clf = clf, features = features, run = 1, experiment = 'ML_Brasileirao_A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
